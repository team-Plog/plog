import os
import logging
import asyncio
from urllib.parse import urlparse

import httpx
from typing import List, Dict, Any, Optional
from datetime import datetime
from sqlalchemy.orm import Session
from app.models.sqlite.models.project_models import OpenAPISpecModel, OpenAPISpecVersionModel, EndpointModel, ParameterModel
from app.schemas.openapi_spec.open_api_spec_register_request import OpenAPISpecRegisterRequest
from app.schemas.openapi_spec.plog_deploy_request import PlogConfigDTO
from app.dto.openapi_parse_result import OpenAPIParseResult
from app.services.openapi.strategy_factory import create_openapi_analysis_context
from app.utils.url_converter import convert_localhost_to_service_url, is_localhost_url
from app.utils.helm_executor import HelmExecutor
from app.utils.helm_values_generator import HelmValuesGenerator
from app.utils.file_writer import FileWriter
from k8s.service_service import ServiceService
from k8s.pod_service import PodService
from app.core.config import settings

logger = logging.getLogger(__name__)


async def analyze_openapi_with_strategy(
    request: OpenAPISpecRegisterRequest,
    db: Session = None,
    convert_url: bool = True,
    conversion_mappings: Optional[Dict[str, Dict[str, str]]] = None
) -> OpenAPISpecModel:
    """
    ì „ëµ íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ OpenAPIë¥¼ ë¶„ì„í•˜ê³  ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.

    Args:
        request: OpenAPI ìŠ¤í™ ë“±ë¡ ìš”ì²­ ê°ì²´
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        convert_url: localhost URLì„ service URLë¡œ ë³€í™˜í• ì§€ ì—¬ë¶€
        conversion_mappings: URL ë³€í™˜ ë§¤í•‘ ì •ë³´ (server_pod_scheduler í˜¸í™˜)

    Returns:
        OpenAPISpecModel: ì™„ì„±ëœ OpenAPI ìŠ¤í™ ëª¨ë¸
    """
    try:
        # 1. ì „ëµ íŒ¨í„´ìœ¼ë¡œ íŒŒì‹± ìˆ˜í–‰
        logger.info(f"ì „ëµ ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì‹œì‘: {request.open_api_url}")
        context = await create_openapi_analysis_context(request)
        logger.info(f"OpenAPI íŒŒì‹± ì‹œì‘: {request.open_api_url}")
        parse_result = await context.parse(request)
        logger.info(f"OpenAPI íŒŒì‹± ì™„ë£Œ: title={parse_result.title}, base_url={parse_result.base_url}, endpoints={len(parse_result.endpoints)}")

        # 2. URL ë³€í™˜ ë¡œì§ (ì¼ê´€ì„± í™•ë³´)
        if convert_url and is_localhost_url(parse_result.base_url):
            if conversion_mappings:
                from app.utils.url_converter import convert_url_with_mapping
                original_base_url = parse_result.base_url
                converted_base_url = convert_url_with_mapping(parse_result.base_url, conversion_mappings)

                if converted_base_url != original_base_url:
                    parse_result.base_url = converted_base_url
                    logger.info(f"URL ë³€í™˜ ì™„ë£Œ: {original_base_url} â†’ {converted_base_url}")
                else:
                    logger.warning(f"URL ë³€í™˜ ì‹¤íŒ¨: {original_base_url} (ë§¤í•‘ ì •ë³´ ì—†ìŒ)")

            else:
                logger.info(f"localhost URL ê°ì§€ë˜ì—ˆì§€ë§Œ ë³€í™˜ ë§¤í•‘ì´ ì—†ìŒ: {parse_result.base_url}")

        # 3. DB ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
        return await create_openapi_spec_from_parse_result(parse_result, request, db)

    except Exception as e:
        logger.error(f"OpenAPI íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        logger.error(f"íŒŒì‹± ì—ëŸ¬ ìƒì„¸ ì •ë³´: {traceback.format_exc()}")
        raise


async def create_openapi_spec_from_parse_result(
    parse_result: OpenAPIParseResult,
    request: OpenAPISpecRegisterRequest,
    db: Session = None
) -> OpenAPISpecModel:
    """
    íŒŒì‹± ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ OpenAPISpecModelì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        parse_result: íŒŒì‹±ëœ OpenAPI ë°ì´í„°
        request: ì›ë³¸ ìš”ì²­ ê°ì²´
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜

    Returns:
        OpenAPISpecModel: ì™„ì„±ëœ OpenAPI ìŠ¤í™ ëª¨ë¸
    """
    if not db:
        # DB ì—†ì´ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬ ë¶ˆê°€
        raise ValueError("ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤")

    # 1. ë™ì¼í•œ base_urlì„ ê°€ì§„ openapi_specì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    existing_spec = db.query(OpenAPISpecModel).filter(
        OpenAPISpecModel.base_url == parse_result.base_url,
        OpenAPISpecModel.project_id == request.project_id
    ).first()

    # 2. ì¡´ì¬í•˜ë©´ ê¸°ì¡´ ê²ƒì„ ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    if existing_spec:
        openapi_spec_model = existing_spec
        logger.info(f"ê¸°ì¡´ OpenAPI ìŠ¤í™ ì‚¬ìš©: {existing_spec.id}")
    else:
        openapi_spec_model = OpenAPISpecModel(
            title=parse_result.title,
            version=parse_result.version,
            base_url=parse_result.base_url,
            project_id=request.project_id,
        )
        logger.info(f"ìƒˆ OpenAPI ìŠ¤í™ ìƒì„±: {parse_result.title}")

    # 3. OpenAPI ìŠ¤í™ ë²„ì „ ìƒì„±
    if existing_spec:
        # ê¸°ì¡´ ë²„ì „ë“¤ì„ ëª¨ë‘ ë¹„í™œì„±í™”
        db.query(OpenAPISpecVersionModel).filter(
            OpenAPISpecVersionModel.open_api_spec_id == existing_spec.id
        ).update({"is_activate": False})
        logger.info(f"ê¸°ì¡´ ë²„ì „ë“¤ ë¹„í™œì„±í™”: spec_id={existing_spec.id}")

    openapi_spec_version = OpenAPISpecVersionModel(
        created_at=datetime.now(),
        commit_hash=getattr(request, 'commit_hash', None),
        is_activate=True,
        open_api_spec_id=openapi_spec_model.id if existing_spec else None
    )

    # 4. endpoint ì €ì¥ & íŒŒë¼ë¯¸í„° íŒŒì‹± (ë°˜ì •ê·œí™”ëœ êµ¬ì¡°)
    all_endpoints = []

    for endpoint_data in parse_result.endpoints:
        endpoint_model = EndpointModel(
            path=endpoint_data.path,
            method=endpoint_data.method,
            summary=endpoint_data.summary,
            description=endpoint_data.description,
            tag_name=endpoint_data.tag_name,
            tag_description=endpoint_data.tag_description,
            openapi_spec_version_id=None  # ë‚˜ì¤‘ì— ì„¤ì •
        )

        # íŒŒë¼ë¯¸í„° ëª¨ë¸ ìƒì„±
        parameters = []
        for param_data in endpoint_data.parameters:
            parameter_model = ParameterModel(
                param_type=param_data.get("param_type", ""),
                name=param_data.get("name", ""),
                required=param_data.get("required", False),
                value_type=param_data.get("value_type", ""),
                title=param_data.get("title", ""),
                description=param_data.get("description", ""),
                value=param_data.get("value")
            )
            parameters.append(parameter_model)

        # endpointì— íŒŒë¼ë¯¸í„° ì—°ê²°
        endpoint_model.parameters = parameters
        all_endpoints.append(endpoint_model)

    # 5. endpointsë¥¼ openapi_spec_versionì— ì—°ê²°
    for endpoint in all_endpoints:
        endpoint.openapi_spec_version = openapi_spec_version
    openapi_spec_version.endpoints = all_endpoints

    # 6. openapi_spec_versionì„ openapi_specì— ì—°ê²°
    if not existing_spec:
        openapi_spec_model.openapi_spec_versions = [openapi_spec_version]
    else:
        openapi_spec_model.openapi_spec_versions.append(openapi_spec_version)

    logger.info(f"OpenAPI ìŠ¤í™ ì²˜ë¦¬ ì™„ë£Œ: {len(all_endpoints)}ê°œ ì—”ë“œí¬ì¸íŠ¸")
    return openapi_spec_model


def save_openapi_spec(db: Session, openapi_spec_model: OpenAPISpecModel) -> OpenAPISpecModel:
    db.add(openapi_spec_model)
    db.commit()
    db.refresh(openapi_spec_model)

    return openapi_spec_model


async def deploy_openapi_spec(db: Session, request: PlogConfigDTO) -> dict:
    """
    PlogConfigDTOë¥¼ ë°›ì•„ì„œ ë°°í¬ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•˜ëŠ” ì„œë¹„ìŠ¤
    
    Args:
        db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        request: PlogConfigDTO ë°°í¬ ìš”ì²­ ë°ì´í„°
        
    Returns:
        dict: ë°°í¬ ê²°ê³¼ ì •ë³´
        
    Raises:
        EnvironmentError: PLOG_HELM_CHART_FOLDER í™˜ê²½ë³€ìˆ˜ê°€ ì—†ì„ ë•Œ
        Exception: ë°°í¬ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨ì‹œ
    """
    try:
        logger.info(f"1. ë°°í¬ í”„ë¡œì„¸ìŠ¤ ì‹œì‘: {request.app_name}")
        
        # 1. PlogConfigDTOë¥¼ Helm values.yamlë¡œ ë³€í™˜
        helm_generator = HelmValuesGenerator()
        values_yaml_content = helm_generator.generate_values_yaml(request)
        
        # 2. PLOG_HELM_CHART_FOLDER í™˜ê²½ë³€ìˆ˜ì—ì„œ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        helm_chart_folder = os.getenv("PLOG_HELM_CHART_FOLDER")
        if not helm_chart_folder:
            raise EnvironmentError("PLOG_HELM_CHART_FOLDER í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # 3. ê¸°ì¡´ values.yaml íŒŒì¼ í™•ì¸ ë° ì œê±°
        from pathlib import Path
        target_file_path = str(Path(helm_chart_folder) / "values.yaml")
        
        if FileWriter.file_exists(target_file_path):
            FileWriter.remove_file(target_file_path)

        # 4. values.yaml íŒŒì¼ ì €ì¥
        saved_path = FileWriter.write_to_path(
            content=values_yaml_content,
            filename="values.yaml",
            base_path=helm_chart_folder,
        )
        
        logger.info(f"2. values.yaml íŒŒì¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {saved_path}")
        # ex) app_name = semi-medeasy -> service_name = semi_medeasy_service
        helm_executor = HelmExecutor()
        deployment_result = await helm_executor.upgrade_install(
            chart_path=helm_chart_folder,
            app_name=request.app_name,
            namespace="test"
        )

        logger.info(f"3. helm íŒ¨í‚¤ì§€ ë°°í¬ ì™„ë£Œ")

        # 7. ë°°í¬ëœ ì„œë¹„ìŠ¤ íƒì§€ ë° OpenAPI ë“±ë¡
        service = ServiceService(namespace="test")
        service_label = {
            "app": request.app_name,
        }
        services_info = service.get_service_by_labels(service_label)
        service_name = services_info[0].get("name")
        service_port = services_info[0].get("ports")[0].get("port")

        logger.info(f"ë°°í¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ë§¤ì¹­ ì„œë¹„ìŠ¤ ì´ë¦„: {service_name}")

        # ì„œë¹„ìŠ¤ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ ëŒ€ê¸°
        service_ready = await _wait_for_service_ready(service_name, timeout=60)
        if service_ready:
            logger.info(f"ì„œë¹„ìŠ¤ ì¤€ë¹„ ì™„ë£Œ: {service_name}")
            
            # Swagger URL ìŠ¤ìº”
            swagger_urls = await _scan_swagger_urls_for_service(service_name)
            
            if swagger_urls:
                logger.info(f"Swagger URL íƒì§€ë¨: {swagger_urls[0]}")
                
                try:
                    # OpenAPI ë“±ë¡ ìš”ì²­ ìƒì„±
                    from pydantic import HttpUrl
                    openapi_request = OpenAPISpecRegisterRequest(
                        project_id=1,  # ê¸°ë³¸ í”„ë¡œì íŠ¸ ID
                        open_api_url=HttpUrl(swagger_urls[0])
                    )

                    parsed_url = urlparse(swagger_urls[0])

                    logger.info(f"parsed_url parsing êµ¬ì¡° íŒŒì•…: {parsed_url}")

                    conversion_mappings = {
                        f"{parsed_url.scheme}://{parsed_url.netloc}": {
                            "service_name": service_name,
                            "service_port": service_port,
                        }
                    }

                    logger.info(f"ë³€í™˜ ë§¤í•‘ ì •ë³´ ìƒì„±: {conversion_mappings}")

                    # OpenAPI ë¶„ì„ ë° ë“±ë¡ (ìƒì„¸ ë¡œê¹…)
                    logger.info(f"OpenAPI ë¶„ì„ ì‹œì‘: {swagger_urls[0]}")

                    analysis_result: OpenAPISpecModel = await analyze_openapi_with_strategy(
                        openapi_request,
                        db=db,
                        convert_url=True,
                        conversion_mappings=conversion_mappings
                    )

                    logger.info(f"OpenAPI ë¶„ì„ ì™„ë£Œ: {analysis_result}")

                    if analysis_result:
                        saved_openapi_spec = save_openapi_spec(db, analysis_result)
                        logger.info(f"OpenAPI ë“±ë¡ ì„±ê³µ: spec_id={saved_openapi_spec.id}")

                except Exception as e:
                    import traceback
                    logger.error(f"OpenAPI ë“±ë¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    logger.error(f"ìƒì„¸ ì—ëŸ¬ ì •ë³´: {traceback.format_exc()}")
        
        logger.info(f"ë°°í¬ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ: {request.app_name}")
        return None
        
    except Exception as e:
        logger.error(f"ë°°í¬ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨ - app: {request.app_name}, error: {str(e)}")
        raise Exception(f"ë°°í¬ í”„ë¡œì„¸ìŠ¤ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")


async def _wait_for_service_ready(service_name: str, timeout: int = 60) -> bool:
    """
    ì§€ì •ëœ ì„œë¹„ìŠ¤ê°€ ì¤€ë¹„ë  ë•Œê¹Œì§€ í´ë§ìœ¼ë¡œ ëŒ€ê¸°
    
    Args:
        service_name: ëŒ€ê¸°í•  ì„œë¹„ìŠ¤ ì´ë¦„
        timeout: ìµœëŒ€ ëŒ€ê¸° ì‹œê°„(ì´ˆ)
        
    Returns:
        bool: ì„œë¹„ìŠ¤ ì¤€ë¹„ ì™„ë£Œ ì—¬ë¶€
    """
    service_service = ServiceService(namespace=settings.KUBERNETES_TEST_NAMESPACE)
    check_interval = 5  # 5ì´ˆë§ˆë‹¤ í™•ì¸
    max_attempts = timeout // check_interval
    
    logger.info(f"ì„œë¹„ìŠ¤ ì¤€ë¹„ í™•ì¸ ì‹œì‘: {service_name} (ìµœëŒ€ {timeout}ì´ˆ ëŒ€ê¸°)")
    
    for attempt in range(max_attempts):
        try:
            services = service_service.get_services()
            service_names = [svc["name"] for svc in services if svc["cluster_ip"] != "None"]
            
            if service_name in service_names:
                logger.info(f"ì„œë¹„ìŠ¤ ì¤€ë¹„ ì™„ë£Œ í™•ì¸ë¨: {service_name} (ì‹œë„ {attempt + 1}/{max_attempts})")
                return True
                
            logger.debug(f"ì„œë¹„ìŠ¤ ì¤€ë¹„ ëŒ€ê¸° ì¤‘: {service_name} (ì‹œë„ {attempt + 1}/{max_attempts})")
            await asyncio.sleep(check_interval)
            
        except Exception as e:
            logger.warning(f"ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)} (ì‹œë„ {attempt + 1}/{max_attempts})")
            await asyncio.sleep(check_interval)
    
    logger.warning(f"ì„œë¹„ìŠ¤ ì¤€ë¹„ ì‹¤íŒ¨: {service_name} ({timeout}ì´ˆ ì´ˆê³¼)")
    return False


async def _scan_swagger_urls_for_service(service_name: str) -> List[str]:
    """
    íŠ¹ì • ì„œë¹„ìŠ¤ì˜ Swagger URLì„ ìŠ¤ìº”
    
    Args:
        service_name: ìŠ¤ìº”í•  ì„œë¹„ìŠ¤ ì´ë¦„
        
    Returns:
        List[str]: ë°œê²¬ëœ Swagger URL ë¦¬ìŠ¤íŠ¸
    """
    service_service = ServiceService(namespace=settings.KUBERNETES_TEST_NAMESPACE)
    pod_service = PodService(namespace=settings.KUBERNETES_TEST_NAMESPACE)
    
    try:
        # ì„œë¹„ìŠ¤ì™€ ë§¤ì¹­ë˜ëŠ” Pod ëª©ë¡ ì¡°íšŒ
        pod_names = service_service.get_pod_names_matching_service(service_name)
        
        if not pod_names:
            logger.warning(f"ì„œë¹„ìŠ¤ì— ë§¤ì¹­ë˜ëŠ” Podì´ ì—†ìŒ: {service_name}")
            return []

        logger.info(f"ğŸ”¥ğŸ”¥ğŸ”¥ pod name debug: {pod_names}")
        
        # SERVER íƒ€ì… Pod ì°¾ê¸°
        server_pods_found = []
        for pod_name in pod_names:
            try:
                detailed_pod_info = pod_service.get_pod_details_with_owner_info(pod_name)

                if detailed_pod_info.get("service_type") == "SERVER":
                    logger.info(f"SERVER Pod ë°œê²¬: {pod_name}")
                    server_pods_found.append(pod_name)

                    # Podì˜ ë ˆì´ë¸”ì„ ì‚¬ìš©í•˜ì—¬ ì„œë¹„ìŠ¤ ì°¾ê¸°
                    services = pod_service.find_services_for_pod(detailed_pod_info["labels"])
                    logger.info(f"Pod {pod_name}ì— ëŒ€ì‘í•˜ëŠ” ì„œë¹„ìŠ¤ ìˆ˜: {len(services)}")

                    if services:
                        # Swagger URL íƒì§€ (ServerPodScheduler ë¡œì§ ì¬ì‚¬ìš©)
                        swagger_urls = await _discover_swagger_urls_with_fallback(services)
                        logger.info(f"Pod {pod_name}ì—ì„œ íƒì§€ëœ Swagger URL ìˆ˜: {len(swagger_urls)}")

                        if swagger_urls:
                            logger.info(f"Swagger URL ë°œê²¬: {swagger_urls}")
                            return swagger_urls
                    else:
                        logger.warning(f"Podì— ëŒ€ì‘í•˜ëŠ” ì„œë¹„ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {pod_name}")

            except Exception as e:
                logger.error(f"Pod ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {pod_name}, error: {str(e)}")
                continue

        if server_pods_found:
            logger.warning(f"SERVER Podì€ ì°¾ì•˜ì§€ë§Œ ì ‘ê·¼ ê°€ëŠ¥í•œ Swagger URLì„ ì°¾ì„ ìˆ˜ ì—†ìŒ. ë°œê²¬ëœ SERVER Pod: {server_pods_found}")
        else:
            logger.warning(f"SERVER íƒ€ì… Podì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {service_name}")
        return []
        
    except Exception as e:
        logger.error(f"Swagger URL ìŠ¤ìº” ì˜¤ë¥˜: {service_name}, error: {str(e)}")
        return []


async def _discover_swagger_urls_with_fallback(services: List[Dict[str, Any]]) -> List[str]:
    """
    ì„œë¹„ìŠ¤ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Swagger URLì„ íƒì§€í•˜ê³ , ì‹¤íŒ¨ ì‹œ NodePortë¡œ fallback ì‹œë„
    (ServerPodSchedulerì˜ ë¡œì§ì„ ì¬ì‚¬ìš©)
    
    Args:
        services: Service ì •ë³´ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        ë°œê²¬ëœ Swagger URL ë¦¬ìŠ¤íŠ¸
    """
    swagger_urls = []
    
    swagger_paths = [
        "/v3/api-docs", "/swagger-ui", "/swagger-ui/index.html",
        "/api/swagger", "/swagger", "/docs", "/api/docs",
        "/openapi.json", "/swagger.json", "/v1/api-docs",
        "/v2/api-docs", "/api-docs"
    ]
    
    for service in services:
        service_name = service["name"]
        cluster_ip = service["cluster_ip"]
        ports = service["ports"]
        service_type = service.get("type", "ClusterIP")
        
        # Try cluster internal URLs
        for port in ports:
            if _is_http_port(port):
                service_url = f"http://{service_name}.{settings.KUBERNETES_TEST_NAMESPACE}.svc.cluster.local:{port}"
                urls_found = await _check_swagger_endpoints(service_url, swagger_paths)
                swagger_urls.extend(urls_found)
                
                if cluster_ip and cluster_ip != "None":
                    cluster_url = f"http://{cluster_ip}:{port}"
                    urls_found = await _check_swagger_endpoints(cluster_url, swagger_paths)
                    swagger_urls.extend(urls_found)
        
        # NodePort fallback
        if service_type == "NodePort":
            node_ports = service.get("node_ports", [])
            port_mappings = service.get("port_mappings", {})
            await _try_nodeport_fallback(service_name, node_ports, port_mappings, swagger_paths, swagger_urls)
    
    return swagger_urls


async def _check_swagger_endpoints(base_url: str, swagger_paths: List[str]) -> List[str]:
    """
    ì£¼ì–´ì§„ base URLì— ëŒ€í•´ swagger pathsë¥¼ ë³‘ë ¬ë¡œ í™•ì¸í•˜ì—¬ ìœ íš¨í•œ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    """
    potential_urls = [f"{base_url}{swagger_path}" for swagger_path in swagger_paths]
    semaphore = asyncio.Semaphore(5)
    
    async def check_single_url_with_semaphore(client, url):
        async with semaphore:
            return await _check_swagger_url_with_client(client, url)
    
    async with httpx.AsyncClient(timeout=3, follow_redirects=True) as client:
        tasks = [(asyncio.create_task(check_single_url_with_semaphore(client, url)), url) 
                for url in potential_urls]
        
        try:
            task_list = [task for task, _ in tasks]
            results = await asyncio.gather(*task_list, return_exceptions=True)
            
            for i, (result, (_, url)) in enumerate(zip(results, tasks)):
                if result is True:
                    return [url]
                    
        except Exception as e:
            logger.error(f"Error in parallel URL checking: {e}")
            raise
        
        return []


async def _try_nodeport_fallback(service_name: str, node_ports: List[int], 
                               port_mappings: Dict[int, int], swagger_paths: List[str], swagger_urls: List[str]):
    """
    NodePort ì„œë¹„ìŠ¤ì— ëŒ€í•´ localhostë¡œ fallback ì‹œë„
    """
    for node_port in node_ports:
        localhost_url = f"http://localhost:{node_port}"
        urls_found = await _check_swagger_endpoints(localhost_url, swagger_paths)
        
        if urls_found:
            swagger_urls.extend(urls_found)


async def _check_swagger_url_with_client(client, url: str) -> bool:
    """
    ì£¼ì–´ì§„ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ URLì´ ìœ íš¨í•œ Swagger ì—”ë“œí¬ì¸íŠ¸ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    """
    try:
        response = await client.get(url)

        if response.status_code == 200:
            content = response.text
            content_lower = content.lower()
            swagger_keywords = [
                "swagger", "openapi", "api documentation", 
                "swagger-ui", "redoc", "rapidoc"
            ]
            keyword_found = any(keyword in content_lower for keyword in swagger_keywords)
            
            if keyword_found:
                return True
                
            # JSON ì‘ë‹µì¸ ê²½ìš° OpenAPI ìŠ¤í™ì¸ì§€ í™•ì¸
            try:
                json_data = response.json()
                json_check = isinstance(json_data, dict) and (
                    "swagger" in json_data or 
                    "openapi" in json_data or 
                    "info" in json_data
                )

                if json_check:
                    return True
            except Exception:
                pass
                
    except Exception:
        pass
        
    return False


def _is_http_port(port: int) -> bool:
    """
    í¬íŠ¸ê°€ HTTP ì„œë¹„ìŠ¤ í¬íŠ¸ì¸ì§€ ì¶”ì •í•©ë‹ˆë‹¤.
    """
    common_http_ports = [80, 8080, 3000, 4000, 5000, 8000, 9000]
    return port in common_http_ports or (8000 <= port <= 9999)
